{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Idea \n",
    "Sometimes, the data we are faced with are the duration of a status.A typical example is studying the length of time between the time you graduate and the time you find a job, i.e., the duration of job search. Suppose we are standing at 2020/12/31.The survey data, which is cross-sectional, typically looks like\n",
    "- Individual 1: graduated at 2020/01/01, find a job at 2020/06/01. Therefore, the duration of his job search is 5 months.\n",
    "- Individual 2: graduated at 2020/03/01, but still looking for job at the time of the survey, 2020/12/31. Therefore, we do know the exact real job search duration for this individual, but we know the duaration is longer than 10 months. \n",
    "<p>The main message from this data set is that: \n",
    "- first, when dealing with such data, we may have <b>censored data</b>, in the sense we cannot observe the real value but rather its lower bound. \n",
    "- Second, the end of the duration means jumping out from this status to another status, and some specific stochastic distribution is needed to depict such a process. \n",
    " <p>Denote the real job search duration as $T^*_i$, whether the individual has already found a job or not as $w_i$($w_i=1$ means 'already found a job', 0 denotes 'still searching' ), and the observed job search duratio (standing at the time point of survey) as $t_i$. Following the general framework in the section 'Missing or censored data', the likelihood function of an individual is therefore \n",
    "    $${f(t_i |x_i,\\theta)}^{w_i}{S(t_i|x_i,\\theta)}^{1-w_i}$$\n",
    "    in whicht $S(t_i |x_i, \\theta)= 1- F(t_i | x_i,\\theta)$. f and F are the density and accumulative probability function of the real duration $T^*$.  This likelihood function is intuitive: at the time of survey, if $i$ has already found a job, then we know the exact $t_i = T^*_i$. If $i$ is till finding a job and his job search has lasted for $t_i$, all we know is that $T^*_i > t_i$\n",
    "    <p>This is the starting point of transition analysis framework. The next task is to discuss the sepcification of $F$ and $f$. In most textbooks, however, we often discuss the specification of $\\lambda(t,x)\\equiv \\frac{f(t|x)}{S(t_i |x_i)}$. This expression implies that\n",
    "        $$f(t)=\\lambda(t)exp\\left[-\\int_{0}^{t}{\\lambda(u)}du\\right], S(t)=exp\\left[-\\int_{0}^{t}{\\lambda(u)}du\\right] \\tag{1}$$\n",
    "        That is, when we determine the expression of $\\lambda(.)$, we know $f$ and $F$ immediately. <b>The $\\lambda(t)$ is called 'harzard function', which measures the 'instant 'possibility of switching out of the status given the individual has been in this status for $t$ period of time.</b>\n",
    "        The following sections give a detailed discussion on how to specify $\\lambda(t,x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportional Harzard (PH)\n",
    "A very intuitive and simple way is to assume that \n",
    "$$\\lambda(t,x)=\\lambda_0(t)h(x)$$\n",
    "In which $\\lambda_0(t)$ is called 'baseline hazard', which does not depend on the $x$. The next step is to specify the $\\lambda_0(t)$ and $h(x)$. Of course, one principle of the specification is that it should be easy to interprete. Another principal is to make (1) easy to calculate. Often we specify $h(x)\\equiv e^{x'\\beta}$(why?). Now we discuss the several possible specification of $\\lambda_0(t)$\n",
    "\n",
    "## Exponetial regression\n",
    "If $$\\lambda_0(t)=e^a$$\n",
    "In which $a$ is a parameter to estimate, then we get the exponential regression.\n",
    "\n",
    "## Weibull Regression\n",
    "If $$\\lambda_0(t)=p t^{p-1}e^a$$ in which $a$ and $p$ are paramter to estimate, then we get weibull regression.\n",
    "\n",
    "## Gompertz Regression\n",
    "If $$\\lambda_0(t)=e^{a+\\gamma t}$$, then we get Gompertz regression. By specifying $\\gamma>0$ or $\\gamma<0$, we can make the baseline harzard increase or decline with $t$. This regression specification is often used in demographics.\n",
    "\n",
    "## Piecewise Constant Harzard \n",
    "A common disadvantage for the above regression, of course, is the monotonicity: the baseline either increases, or decreases, or keeps constant as $t$ increase. This may not be the realistic case. For example, infants and elder people have high death harzard, while young age people have low death harzard. To depict such a baseline harzard pattern, a natural way is to use piece-wise expression of baseline harzard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelarated Failure Time Model\n",
    "Proportional harzard model assumes that the baseline harzard does not vary with $x$. Taking Gompertz regression and the job search as example. The gompertz regression specification implies that the two individuals have different harzard of finding a job for a given job search duration $t$. The 'change' of the harzard of finding job with time, however, is the same for these two individuals, since they have the same expression of baseline hazard. In reality, however, it is totally possible that one individual have a faster change of harzard with time than the other. To depict such a potential difference in the 'change' of the harzard with time, we want to make the baseline hazard also a function of $x$.\n",
    "There we can write the hazard function \n",
    "$$\\lambda(t,x)=\\lambda_0(e^{-x'\\beta}t)x'\\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues of unobservable heterogeneity\n",
    "What if there is unobersable heterogeneity in the $\\lambda(x_i,t)$? Say, \n",
    "$$\\lambda_i(x_i,t,v_i)=\\lambda_0(t)e^{x'_i\\beta}v_i$$\n",
    "in which $v_i$ are something that cannot be observed. \n",
    "Therefore we have \n",
    "$$S(t,x_i,v_i)= exp\\left[-\\int_{0}^{t}{\\lambda(u,x_i,v_i)}du\\right]$$\n",
    "Of course, since there is unobservable $v_i$, we need to take integral over $v_i$ before we write down the likelihood function. To take the integrals, we naturally need to assume a distribution of $v_i$.\n",
    "$$\\lambda_i(x_i,t)=\\int{\\lambda_0(t)e^{x'_i\\beta}v_ig(v_i)}dv_i=\\lambda_0(t)e^{x'_i\\beta}\\int{v_i g(v_i)}dv_i$$\n",
    "$$S(x_i,t)=\\int{{   \\left[ exp\\left(-e^{x'_i\\beta}\\int_{0}^{t}{\\lambda_0(t)}du\\right)\\right]   }^{v_i} g(v_i)dv_i}$$\n",
    "It is better to choose $g()$ such that the above expressions have analytical expression. Having the above expression we are ready to apply MLE. <b> But what is bad about such unobserved hetergeneity?</b>\n",
    "<p> A very natural logic is as follows. Suppose we do not consider the heterogeity when writing the likelihood. Suppose that sample, there are many people who find job quickly, i.e., they have small $t$. What will this affect the estimation? This will in general makes the estimation on $\\lambda_0(t)$, the basic harzard, high. <b>But can we be sure that many people find quickly right because that the baseline harzard is high? One alternative reason is that, for these part of people, they have some unbservable characteritics (not in $x$),say, very high ability of job search ability, that makes them find jobs quickly, while the rest spend a long time on job search since they have low job search ability</b>. If most inviduals in the sample are high ability people, then the average job find time may be low, although the baseline harzard may even be low. A MLE without considering such composition effect brought by unobservable characteristics, therefore, leads to inconsistent estimation on the baseline harzard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
